
* Compiling  

Branch: def1

[skylake|spark]$ ./build/mvn  -DskipTests -Dcheckstyle.skip=true package -pl core

Takes <1 minute 

* Testing

/Presumably call the HTTP API/?

http://localhost:4040/api/v1/applications/local-1525801590553/try-deflate

::TODO:: Make script for getting the application ID and calling the right API 

#+BEGIN_SRC bash

#!/bin/bash 
appid = curl http://localhost:4040/api/v1/applications | jq '.[-1].id'

curl http://localhost:4040/api/v1/applications/$appid/try-deflate

#+END_SRC 

* Running 

Figure out a way to easily run/terminate long-running Spark job (SparkPi?) that we can use to test executor loss etc. 

#+BEGIN_SRC bash

./bin/run-example SparkPi 100000 

#+END_SRC 

:TODO: Num executors, connect to existing master? etc. 


* Gen Spark 

There is now a PeriodicRDDCheckpointer!!!

/rdd/util/PeriodicRDDCheckpointer.scala

* UI Server location 

    attachHandler(createRedirectHandler(
      "/stages/stage/kill", "/stages/", stagesTab.handleKillRequest,
      httpMethods = Set("GET", "POST")))
in 

core/src/main/scala/org/apache/spark/ui/SparkUI.scala 

/core/src/main/scala/org/apache/spark/ui/scope/RDDOperationGraph.scala 

* HTTP API Endpoint 

core/src/main/scala/org/apache/spark/status/api/v1/

/core/src/main/scala/org/apache/spark/status/api/v1/OneApplicationResource.scala 

ApiRootResource.scala : API endpoints registered using @Path("deflate") 
api.scala : class definitions 


* Rest API 

The main idea (AFAIR) was to create a bunch of HTTP endpoints that we can then call. 

Executors killed using the blacklist mechanism. 

Information for deflation: isShuffle, num-stages, progress, etc. 

TODO: 

* History Server 

Keep record of operation times to get recomputation time and other task details

/core/src/main/scala/org/apache/spark/deploy/history/


* Status 

Most of the useful metrics are collected in: 
core/src/main/scala/org/apache/spark/status/LiveEntity.scala

TaskInfo 

** AppStatusStore 

can create frp, AppStatusStore.createLiveStore(conf)

or use the one already created in sparkcontext.


* Executor Blacklisting 

scheduler checks if an executor is blacklisted before every scheduling decision.

scheduler/TaskSetBlackList.scala : add to blacklistedExecs collection. (/thats it?/)

updateBlackListForFailedTask adds the exec/node to the above list. Called by : ::TODO:: 

SparkListenerBus event!

sched/BlackListTracker.scala : determines whether to blacklist based on task failures. This also has isExecutorBlackListed, which is different from isExecutorBlackListedForTaskSet in the TaskSetBlackList file 

So, we add an executor to the list that BlackListTracker maintains? 

Alternatively, can use TaskSchedulerImpl.scala:removeExecutor(id, reason), which has the same effect? So what's the whole point of blacklisting?

** Big question: Blacklist or remove executors

*** Blacklist 
- easier to remove from blacklist later

*** Removing
- Sure about loss of Resources 
- Executors added through resource offers. In coarse grained mode, presumably this is only called on slave startup, and so once an executor is removed, we cannot be re-added?

XXX THere is a developerApi killExecutors in SparkContext.scala that we can use directly? Works as long as we dont have dynamic allocation turned on. Can just use that instead of the blacklisting mechanism? 



**** TODO 

 ::DONE::  - Get stages 
- Get current task information for each stage 
- Reclaim fraction parsing and logging 
- Infer shuffle using Wide/narrow dependency? 
::DONE:: - Infer if a task is a shuffle based on bytes read etc 
- Executor killing/maintenance/black-list? 
- Executor respawning
::DONE:: - Num tasks remaining in a stage can be a good heuristic? 
- get correct task status string instead of "Running"
  

Can use hosttoexecutors in TaskSchedulerImpl for sacrificing executors 
